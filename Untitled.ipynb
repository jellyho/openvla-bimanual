{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d8a5c03-50a3-46be-8bc3-4c6e32745726",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-30 20:54:48.180068: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-30 20:54:48.209138: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-30 20:54:48.209188: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-30 20:54:48.209934: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-30 20:54:48.215024: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-30 20:54:49.016334: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import deque\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "import draccus\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import tqdm\n",
    "from accelerate import PartialState\n",
    "from peft import LoraConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForVision2Seq, AutoProcessor, BitsAndBytesConfig\n",
    "from transformers.modeling_outputs import CausalLMOutputWithPast\n",
    "\n",
    "import wandb\n",
    "from prismatic.models.backbones.llm.prompting import PurePromptBuilder, VicunaV15ChatPromptBuilder\n",
    "from prismatic.util.data_utils import PaddedCollatorForActionPrediction\n",
    "from prismatic.vla.action_tokenizer import ActionTokenizer\n",
    "from prismatic.vla.datasets.rlds.utils.data_utils import save_dataset_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2174f3c3-696a-46e0-8156-886d9cf5f873",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinetuneConfig:\n",
    "    # fmt: off\n",
    "    vla_path: str = \"openvla/openvla-7b\"                            # Path to OpenVLA model (on HuggingFace Hub)\n",
    "\n",
    "    # Directory Paths\n",
    "    data_root_dir: Path = Path(\"/home/jellyho/tensorflow_datasets\")        # Path to Open-X dataset directory\n",
    "    dataset_name: str = \"onearm_clean_joint_pos\"                                # Name of fine-tuning dataset (e.g., `droid_wipe`)\n",
    "    run_root_dir: Path = Path(\"/home/jellyho/openvla_run\")                               # Path to directory to store logs & checkpoints\n",
    "    adapter_tmp_dir: Path = Path(\"/home/jellyho/openvla_tmp\")                     # Temporary directory for LoRA weights before fusing\n",
    "\n",
    "    # Fine-tuning Parameters\n",
    "    batch_size: int = 2                                       # Fine-tuning batch size\n",
    "    max_steps: int = 200_000                                        # Max number of fine-tuning steps\n",
    "    save_steps: int = 1000                                          # Interval for checkpoint saving\n",
    "    learning_rate: float = 2e-5                                     # Fine-tuning learning rate\n",
    "    grad_accumulation_steps: int = 4                                # Gradient accumulation steps\n",
    "    image_aug: bool = False                                       # Whether to train with image augmentations\n",
    "    shuffle_buffer_size: int = 100_000                              # Dataloader shuffle buffer size (can reduce if OOM)\n",
    "\n",
    "    # LoRA Arguments\n",
    "    use_lora: bool = True                                           # Whether to use LoRA fine-tuning\n",
    "    lora_rank: int = 64                                           # Rank of LoRA weight matrix\n",
    "    lora_dropout: float = 0.0                                       # Dropout applied to LoRA weights\n",
    "    use_quantization: bool = False                                  # Whether to 4-bit quantize VLA for LoRA fine-tuning\n",
    "                                                                    #   => CAUTION: Reduces memory but hurts performance\n",
    "\n",
    "    # Tracking Parameters\n",
    "    wandb_project: str = \"openvla\"                                  # Name of W&B project to log to (use default!)\n",
    "    wandb_entity: str = \"onearm_clean\" \n",
    "\n",
    "cfg = FinetuneConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee5f434a-3ce1-48c0-9ae0-b9fdd0d8325e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning OpenVLA Model `openvla/openvla-7b` on `onearm_clean_joint_pos`\n"
     ]
    }
   ],
   "source": [
    "print(f\"Fine-tuning OpenVLA Model `{cfg.vla_path}` on `{cfg.dataset_name}`\")\n",
    "\n",
    "# [Validate] Ensure GPU Available & Set Device / Distributed Context\n",
    "assert torch.cuda.is_available(), \"Fine-tuning assumes at least one GPU is available!\"\n",
    "distributed_state = PartialState()\n",
    "# torch.cuda.set_device(device_id := distributed_state.local_process_index)\n",
    "torch.cuda.set_device(device_id := 0)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Quantization Config =>> only if LoRA fine-tuning\n",
    "quantization_config = None\n",
    "if cfg.use_quantization:\n",
    "    assert cfg.use_lora, \"Quantized training only supported for LoRA fine-tuning!\"\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True, bnb_4bit_compute_dtype=torch.bfloat16, bnb_4bit_quant_type=\"nf4\"\n",
    "    )\n",
    "\n",
    "# Load OpenVLA Processor and Model using HF AutoClasses\n",
    "processor = AutoProcessor.from_pretrained(cfg.vla_path, trust_remote_code=True)\n",
    "\n",
    "# Create Action Tokenizer\n",
    "action_tokenizer = ActionTokenizer(processor.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5fdf4da-7c83-4825-94d0-5a973586f829",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-30 20:55:02.508896: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">08/30 [20:55:02] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> | &gt;&gt; <span style=\"font-weight: bold\">[</span>*<span style=\"font-weight: bold\">]</span> Loading existing dataset statistics from                       <a href=\"file:///home/jellyho/LG/model/openvla-bimanual/prismatic/vla/datasets/rlds/utils/data_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/jellyho/LG/model/openvla-bimanual/prismatic/vla/datasets/rlds/utils/data_utils.py#208\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">208</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span>         <span style=\"color: #800080; text-decoration-color: #800080\">/home/jellyho/tensorflow_datasets/onearm_clean_joint_pos/1.0.0/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">dataset_</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span>         <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">statistics_148a7f78560ff30a0a1dad9b7c50d732490e58a45bac219f0310b24fb627</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span>         <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">c2a7.json.</span>                                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m08/30 [20:55:02]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m | >> \u001b[1m[\u001b[0m*\u001b[1m]\u001b[0m Loading existing dataset statistics from                       \u001b]8;id=294182;file:///home/jellyho/LG/model/openvla-bimanual/prismatic/vla/datasets/rlds/utils/data_utils.py\u001b\\\u001b[2mdata_utils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=848110;file:///home/jellyho/LG/model/openvla-bimanual/prismatic/vla/datasets/rlds/utils/data_utils.py#208\u001b\\\u001b[2m208\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                 \u001b[0m         \u001b[35m/home/jellyho/tensorflow_datasets/onearm_clean_joint_pos/1.0.0/\u001b[0m\u001b[95mdataset_\u001b[0m \u001b[2m                 \u001b[0m\n",
       "\u001b[2;36m                 \u001b[0m         \u001b[95mstatistics_148a7f78560ff30a0a1dad9b7c50d732490e58a45bac219f0310b24fb627\u001b[0m \u001b[2m                 \u001b[0m\n",
       "\u001b[2;36m                 \u001b[0m         \u001b[95mc2a7.json.\u001b[0m                                                              \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-30 20:55:02.956838: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################################\n",
      "# Loading the following 1 datasets (incl. sampling weight):                         #\n",
      "# onearm_clean_joint_pos: ==================================================1.000000 #\n",
      "######################################################################################\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">08/30 [20:55:03] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> | &gt;&gt; <span style=\"font-weight: bold\">[</span>*<span style=\"font-weight: bold\">]</span> Threads per Dataset: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>                                          <a href=\"file:///home/jellyho/LG/model/openvla-bimanual/prismatic/vla/datasets/rlds/dataset.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">dataset.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/jellyho/LG/model/openvla-bimanual/prismatic/vla/datasets/rlds/dataset.py#531\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">531</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m08/30 [20:55:03]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m | >> \u001b[1m[\u001b[0m*\u001b[1m]\u001b[0m Threads per Dataset: \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m                                          \u001b]8;id=913550;file:///home/jellyho/LG/model/openvla-bimanual/prismatic/vla/datasets/rlds/dataset.py\u001b\\\u001b[2mdataset.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=907108;file:///home/jellyho/LG/model/openvla-bimanual/prismatic/vla/datasets/rlds/dataset.py#531\u001b\\\u001b[2m531\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> | &gt;&gt; <span style=\"font-weight: bold\">[</span>*<span style=\"font-weight: bold\">]</span> Reads per Dataset: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>                                            <a href=\"file:///home/jellyho/LG/model/openvla-bimanual/prismatic/vla/datasets/rlds/dataset.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">dataset.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/jellyho/LG/model/openvla-bimanual/prismatic/vla/datasets/rlds/dataset.py#532\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">532</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m | >> \u001b[1m[\u001b[0m*\u001b[1m]\u001b[0m Reads per Dataset: \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m                                            \u001b]8;id=341946;file:///home/jellyho/LG/model/openvla-bimanual/prismatic/vla/datasets/rlds/dataset.py\u001b\\\u001b[2mdataset.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=682550;file:///home/jellyho/LG/model/openvla-bimanual/prismatic/vla/datasets/rlds/dataset.py#532\u001b\\\u001b[2m532\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> | &gt;&gt; <span style=\"font-weight: bold\">[</span>*<span style=\"font-weight: bold\">]</span> Constructing datasets<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                          <a href=\"file:///home/jellyho/LG/model/openvla-bimanual/prismatic/vla/datasets/rlds/dataset.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">dataset.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/jellyho/LG/model/openvla-bimanual/prismatic/vla/datasets/rlds/dataset.py#535\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">535</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m | >> \u001b[1m[\u001b[0m*\u001b[1m]\u001b[0m Constructing datasets\u001b[33m...\u001b[0m                                          \u001b]8;id=377309;file:///home/jellyho/LG/model/openvla-bimanual/prismatic/vla/datasets/rlds/dataset.py\u001b\\\u001b[2mdataset.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=642744;file:///home/jellyho/LG/model/openvla-bimanual/prismatic/vla/datasets/rlds/dataset.py#535\u001b\\\u001b[2m535\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-30 20:55:03.397565: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">08/30 [20:55:04] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> | &gt;&gt; <span style=\"font-weight: bold\">[</span>*<span style=\"font-weight: bold\">]</span> Applying frame transforms on dataset<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                           <a href=\"file:///home/jellyho/LG/model/openvla-bimanual/prismatic/vla/datasets/rlds/dataset.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">dataset.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/jellyho/LG/model/openvla-bimanual/prismatic/vla/datasets/rlds/dataset.py#575\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">575</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m08/30 [20:55:04]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m | >> \u001b[1m[\u001b[0m*\u001b[1m]\u001b[0m Applying frame transforms on dataset\u001b[33m...\u001b[0m                           \u001b]8;id=442396;file:///home/jellyho/LG/model/openvla-bimanual/prismatic/vla/datasets/rlds/dataset.py\u001b\\\u001b[2mdataset.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=91483;file:///home/jellyho/LG/model/openvla-bimanual/prismatic/vla/datasets/rlds/dataset.py#575\u001b\\\u001b[2m575\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import importlib\n",
    "import prismatic.vla.datasets\n",
    "window_size = 1\n",
    "future_action_window_size = 29\n",
    "# Force reload the module\n",
    "importlib.reload(prismatic.vla.datasets)\n",
    "\n",
    "from prismatic.vla.datasets import RLDSBatchTransform, RLDSDataset\n",
    "\n",
    "batch_transform = RLDSBatchTransform(\n",
    "    action_tokenizer,\n",
    "    processor.tokenizer,\n",
    "    image_transform=processor.image_processor.apply_transform,\n",
    "    prompt_builder_fn=PurePromptBuilder if \"v01\" not in cfg.vla_path else VicunaV15ChatPromptBuilder,\n",
    "    window_size=window_size,\n",
    "    future_action_window_size=future_action_window_size\n",
    ")\n",
    "# batch_transform = lambda x: x\n",
    "#INFO\n",
    "vla_dataset = RLDSDataset(\n",
    "    cfg.data_root_dir,\n",
    "    cfg.dataset_name,\n",
    "    batch_transform,\n",
    "    resize_resolution=(224, 224),\n",
    "    shuffle_buffer_size=cfg.shuffle_buffer_size,\n",
    "    image_aug=cfg.image_aug,\n",
    "    window_size=window_size,\n",
    "    future_action_window_size=future_action_window_size\n",
    ")\n",
    "collator = PaddedCollatorForActionPrediction(\n",
    "    processor.tokenizer.model_max_length, processor.tokenizer.pad_token_id, padding_side=\"right\"\n",
    ")\n",
    "dataloader = DataLoader(\n",
    "    vla_dataset,\n",
    "    batch_size=cfg.batch_size,\n",
    "    sampler=None,\n",
    "    collate_fn=collator,\n",
    "    num_workers=0,  # Important =>> Set to 0 if using RLDS; TFDS rolls its own parallelism!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f49f30c0-bce9-471a-b494-e8fe4f6f5a1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for batch in dataloader:\n",
    "    b = batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6d45c23-3224-4b19-a475-b2445734f921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100, 31864, 31786, 31901, 31953, 31870,\n",
       "         31785, 31744, 31864, 31786, 31901, 31953, 31870, 31785, 31744, 31864,\n",
       "         31785, 31900, 31953, 31870, 31785, 31744, 31864, 31785, 31900, 31953,\n",
       "         31871, 31785, 31744, 31864, 31784, 31899, 31953, 31871, 31785, 31744,\n",
       "         31864, 31784, 31899, 31953, 31872, 31785, 31744, 31864, 31784, 31898,\n",
       "         31953, 31872, 31785, 31744, 31864, 31783, 31897, 31953, 31873, 31785,\n",
       "         31744, 31864, 31783, 31896, 31953, 31874, 31785, 31744, 31864, 31783,\n",
       "         31896, 31953, 31876, 31785, 31744, 31864, 31782, 31895, 31953, 31877,\n",
       "         31785, 31744, 31864, 31782, 31894, 31953, 31878, 31785, 31744, 31864,\n",
       "         31781, 31894, 31953, 31879, 31785, 31744, 31864, 31781, 31893, 31953,\n",
       "         31881, 31785, 31744, 31864, 31781, 31892, 31953, 31882, 31785, 31744,\n",
       "         31864, 31780, 31892, 31953, 31884, 31785, 31744, 31864, 31780, 31891,\n",
       "         31953, 31885, 31785, 31744, 31864, 31780, 31890, 31953, 31887, 31785,\n",
       "         31744, 31864, 31779, 31889, 31953, 31888, 31785, 31744, 31864, 31779,\n",
       "         31889, 31953, 31890, 31785, 31744, 31864, 31778, 31888, 31953, 31891,\n",
       "         31785, 31744, 31864, 31778, 31888, 31953, 31893, 31785, 31744, 31864,\n",
       "         31777, 31887, 31953, 31895, 31785, 31744, 31864, 31777, 31887, 31953,\n",
       "         31895, 31785, 31757, 31864, 31777, 31887, 31953, 31895, 31785, 31770,\n",
       "         31864, 31777, 31887, 31954, 31895, 31785, 31783, 31864, 31777, 31887,\n",
       "         31954, 31894, 31785, 31795, 31864, 31777, 31887, 31954, 31894, 31785,\n",
       "         31808, 31864, 31777, 31887, 31954, 31894, 31785, 31821, 31864, 31777,\n",
       "         31887, 31953, 31894, 31785, 31834,     2,  -100],\n",
       "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100, 31941, 31779, 31939, 31955,\n",
       "         31868, 31895, 31872, 31941, 31777, 31942, 31955, 31869, 31895, 31872,\n",
       "         31941, 31775, 31945, 31955, 31869, 31895, 31872, 31941, 31773, 31949,\n",
       "         31954, 31870, 31895, 31872, 31942, 31771, 31952, 31954, 31871, 31895,\n",
       "         31872, 31942, 31769, 31955, 31954, 31873, 31895, 31872, 31942, 31767,\n",
       "         31959, 31954, 31874, 31895, 31872, 31943, 31765, 31962, 31954, 31876,\n",
       "         31896, 31872, 31943, 31763, 31966, 31954, 31879, 31896, 31872, 31943,\n",
       "         31761, 31968, 31954, 31878, 31896, 31866, 31943, 31760, 31971, 31954,\n",
       "         31875, 31896, 31859, 31943, 31759, 31973, 31954, 31872, 31896, 31853,\n",
       "         31943, 31758, 31974, 31954, 31869, 31896, 31846, 31943, 31757, 31976,\n",
       "         31954, 31867, 31896, 31840, 31943, 31757, 31977, 31953, 31865, 31896,\n",
       "         31834, 31943, 31756, 31979, 31953, 31863, 31896, 31827, 31943, 31755,\n",
       "         31980, 31953, 31861, 31896, 31821, 31943, 31755, 31981, 31953, 31859,\n",
       "         31896, 31815, 31943, 31754, 31983, 31953, 31857, 31896, 31808, 31943,\n",
       "         31753, 31984, 31953, 31856, 31896, 31802, 31943, 31753, 31985, 31953,\n",
       "         31854, 31896, 31795, 31943, 31752, 31986, 31953, 31853, 31896, 31789,\n",
       "         31943, 31752, 31987, 31953, 31852, 31896, 31783, 31943, 31751, 31988,\n",
       "         31953, 31851, 31896, 31776, 31943, 31751, 31989, 31953, 31850, 31896,\n",
       "         31770, 31943, 31751, 31989, 31953, 31849, 31896, 31764, 31943, 31750,\n",
       "         31990, 31953, 31848, 31896, 31757, 31943, 31750, 31991, 31953, 31847,\n",
       "         31896, 31751, 31943, 31749, 31992, 31953, 31846, 31896, 31744, 31943,\n",
       "         31749, 31992, 31952, 31844, 31895, 31744,     2]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae8fda22-9add-42c6-b200-78c6f07d3697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,   512, 29901,  1724,  3158,   881,   278, 19964,  2125,   304,\n",
       "          5839,   701,   278, 18002,   322,  1925,   372,   297,   278, 25972,\n",
       "         29973,    13,  3744, 29901, 29871, 31864, 31786, 31901, 31953, 31870,\n",
       "         31785, 31744, 31864, 31786, 31901, 31953, 31870, 31785, 31744, 31864,\n",
       "         31785, 31900, 31953, 31870, 31785, 31744, 31864, 31785, 31900, 31953,\n",
       "         31871, 31785, 31744, 31864, 31784, 31899, 31953, 31871, 31785, 31744,\n",
       "         31864, 31784, 31899, 31953, 31872, 31785, 31744, 31864, 31784, 31898,\n",
       "         31953, 31872, 31785, 31744, 31864, 31783, 31897, 31953, 31873, 31785,\n",
       "         31744, 31864, 31783, 31896, 31953, 31874, 31785, 31744, 31864, 31783,\n",
       "         31896, 31953, 31876, 31785, 31744, 31864, 31782, 31895, 31953, 31877,\n",
       "         31785, 31744, 31864, 31782, 31894, 31953, 31878, 31785, 31744, 31864,\n",
       "         31781, 31894, 31953, 31879, 31785, 31744, 31864, 31781, 31893, 31953,\n",
       "         31881, 31785, 31744, 31864, 31781, 31892, 31953, 31882, 31785, 31744,\n",
       "         31864, 31780, 31892, 31953, 31884, 31785, 31744, 31864, 31780, 31891,\n",
       "         31953, 31885, 31785, 31744, 31864, 31780, 31890, 31953, 31887, 31785,\n",
       "         31744, 31864, 31779, 31889, 31953, 31888, 31785, 31744, 31864, 31779,\n",
       "         31889, 31953, 31890, 31785, 31744, 31864, 31778, 31888, 31953, 31891,\n",
       "         31785, 31744, 31864, 31778, 31888, 31953, 31893, 31785, 31744, 31864,\n",
       "         31777, 31887, 31953, 31895, 31785, 31744, 31864, 31777, 31887, 31953,\n",
       "         31895, 31785, 31757, 31864, 31777, 31887, 31953, 31895, 31785, 31770,\n",
       "         31864, 31777, 31887, 31954, 31895, 31785, 31783, 31864, 31777, 31887,\n",
       "         31954, 31894, 31785, 31795, 31864, 31777, 31887, 31954, 31894, 31785,\n",
       "         31808, 31864, 31777, 31887, 31954, 31894, 31785, 31821, 31864, 31777,\n",
       "         31887, 31953, 31894, 31785, 31834,     2, 32000],\n",
       "        [    1,   512, 29901,  1724,  3158,   881,   278, 19964,  2125,   304,\n",
       "          5839,   701,   278,  7933,   508,   322,  1925,   372,   297,   278,\n",
       "         25972, 29973,    13,  3744, 29901, 29871, 31941, 31779, 31939, 31955,\n",
       "         31868, 31895, 31872, 31941, 31777, 31942, 31955, 31869, 31895, 31872,\n",
       "         31941, 31775, 31945, 31955, 31869, 31895, 31872, 31941, 31773, 31949,\n",
       "         31954, 31870, 31895, 31872, 31942, 31771, 31952, 31954, 31871, 31895,\n",
       "         31872, 31942, 31769, 31955, 31954, 31873, 31895, 31872, 31942, 31767,\n",
       "         31959, 31954, 31874, 31895, 31872, 31943, 31765, 31962, 31954, 31876,\n",
       "         31896, 31872, 31943, 31763, 31966, 31954, 31879, 31896, 31872, 31943,\n",
       "         31761, 31968, 31954, 31878, 31896, 31866, 31943, 31760, 31971, 31954,\n",
       "         31875, 31896, 31859, 31943, 31759, 31973, 31954, 31872, 31896, 31853,\n",
       "         31943, 31758, 31974, 31954, 31869, 31896, 31846, 31943, 31757, 31976,\n",
       "         31954, 31867, 31896, 31840, 31943, 31757, 31977, 31953, 31865, 31896,\n",
       "         31834, 31943, 31756, 31979, 31953, 31863, 31896, 31827, 31943, 31755,\n",
       "         31980, 31953, 31861, 31896, 31821, 31943, 31755, 31981, 31953, 31859,\n",
       "         31896, 31815, 31943, 31754, 31983, 31953, 31857, 31896, 31808, 31943,\n",
       "         31753, 31984, 31953, 31856, 31896, 31802, 31943, 31753, 31985, 31953,\n",
       "         31854, 31896, 31795, 31943, 31752, 31986, 31953, 31853, 31896, 31789,\n",
       "         31943, 31752, 31987, 31953, 31852, 31896, 31783, 31943, 31751, 31988,\n",
       "         31953, 31851, 31896, 31776, 31943, 31751, 31989, 31953, 31850, 31896,\n",
       "         31770, 31943, 31751, 31989, 31953, 31849, 31896, 31764, 31943, 31750,\n",
       "         31990, 31953, 31848, 31896, 31757, 31943, 31750, 31991, 31953, 31847,\n",
       "         31896, 31751, 31943, 31749, 31992, 31953, 31846, 31896, 31744, 31943,\n",
       "         31749, 31992, 31952, 31844, 31895, 31744,     2]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['input_ids']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
